{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome","text":"<p>Welcome to Documentation Wiki on CVs and how to use them</p> <p>Documentation in progress</p> <p>The contents of the pages are currently in development, and many aspects still in flux. </p>"},{"location":"#projects","title":"Projects","text":"<p>Currently there are several projects available. These are:</p> <ul> <li><code>CMIP6Plus</code> - the current iteration of CMIP6 related sumbissions allowing us to test and prototype cutting edge improvements to usability and infrastructure and assess their suitability going forward. </li> <li><code>INPUT4MIPs</code> - forcings</li> <li><code>OBS4MIPs</code> - observations</li> </ul> <p>The structure of this documentation will be allow the subtitution of your relevant mip in the <code>&lt;mip_name&gt;</code> tags. Should your MIP not be features, please speak to us regarding resources and requirements. </p>"},{"location":"#useful-links","title":"Useful Links","text":"<p>There are number of links that may infulence your workflow. Many of these can be found on the  CMIP-IPO website .</p>"},{"location":"#iframe-test","title":"iframe test","text":""},{"location":"#project-layout","title":"Project layout","text":"<pre><code>mkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.\n</code></pre>"},{"location":"99_Acknowlegements/","title":"Acknowledgement","text":"<p>The work within most repositories can be attributed to a large number of contributers. A collection of those involved can be found here. </p>"},{"location":"99_Acknowlegements/#mip-cmor-tables","title":"MIP CMOR Tables","text":"<p>The repository content has been developed by climate and computer scientists representing the Coupled Model Intercomparison Project phase 6 (CMIP6) and earlier phases, including those from climate modeling groups and model intercomparison projects (MIPs) worldwide. A special mention to Dr. Martin Juckes from the UK Centre for Environmental Data Analysis (CEDA) for leading efforts in the CMIP6 Data Request. The structure of repository content and tools required to maintain it was developed by climate and computer scientists from the Program for Climate Model Diagnosis and Intercomparison (PCMDI) at Lawrence Livermore National Laboratory (LLNL) and the UK MetOffice, with assistance from colleagues at the Coupled Model Intercomparison Project International Project Office (CMIP-IPO), the Deutsches Klimarechenzentrum (DKRZ) in Germany and the members of the Infrastructure for the European Network for Earth System Modelling (IS-ENES) consortium.</p> <p>This work is sponsored by the Regional and Global Model Analysis (RGMA) program of the Earth and Environmental Systems Sciences Division (EESSD) in the Office of Biological and Environmental Research (BER) within the Department of Energy's (DOE) Office of Science (OS). The work at PCMDI is performed under the auspices of the U.S. Department of Energy by Lawrence Livermore National Laboratory under Contract DE-AC52-07NA27344.</p> <p> </p>"},{"location":"99_Acknowlegements/#cmip6plus-cvs","title":"CMIP6Plus CVS","text":"<p>The repository content has been collected from many contributors representing the Coupled Model Intercomparison Project phase 6+ (CMIP6Plus), including those from climate modeling groups and model intercomparison projects (MIPs) worldwide. The structure of content and tools required to maintain it was developed by climate and computer scientists from the Coupled Model Intercomparison Project International Project Office (CMIP-IPO), the Program for Climate Model Diagnosis and Intercomparison (PCMDI) at Lawrence Livermore National Laboratory (LLNL), and the UK MetOffice, with assistance from colleagues at the UK Centre for Environmental Data Analysis (CEDA), the Deutsches Klimarechenzentrum (DKRZ) in Germany and the members of the Infrastructure for the European Network for Earth System Modelling (IS-ENES) consortium.</p> <p>This work is sponsored by the Regional and Global Model Analysis (RGMA) program of the Earth and Environmental Systems Sciences Division (EESSD) in the Office of Biological and Environmental Research (BER) within the Department of Energy's (DOE) Office of Science (OS). The work at PCMDI is performed under the auspices of the U.S. Department of Energy by Lawrence Livermore National Laboratory under Contract DE-AC52-07NA27344.</p> <p> </p>"},{"location":"99_Acknowlegements/#wiki-forms-automations-and-infrastructure-work","title":"Wiki, Forms, Automations, and Infrastructure work.","text":"<p>CMIP IPO (Daniel Ellis), LLNL (Paul Durack), MOHC (Matthew Mizielinski)</p>"},{"location":"CMIP6Plus/","title":"What is CMIP6Plus","text":"Description Repository Status <p>This page outlines building guidance to register and contribute to the CMIP6Plus phase. We will update this page with new information as it becomes available.</p>"},{"location":"CMIP6Plus/#current-guidance-for-contributors","title":"Current guidance for contributors:","text":"<ul> <li>Add a new model/source_id</li> </ul>"},{"location":"CMIP6Plus/#additional-resources","title":"Additional resources:","text":"<ul> <li>MIP tables</li> <li>Registered Model Intercomparison Project (MIPs)</li> </ul>"},{"location":"CMIP6Plus/Automations/gencv_action/","title":"[Action] To run create_CV","text":"<p>The flow of the github action which run when a new commits are pushed to a branch. </p> <pre><code>graph TD\n  style AA fill:#003366,stroke:#ffffff,stroke-width:2px;\n  style BB fill:#005cbf,stroke:#ffffff,stroke-width:2px;\n  style CC fill:#0078d4,stroke:#ffffff,stroke-width:2px;\n  style DD fill:#009be1,stroke:#ffffff,stroke-width:2px;\n  style EE fill:#00a8e8,stroke:#ffffff,stroke-width:2px;\n  style FF fill:#00adef,stroke:#ffffff,stroke-width:2px;\n  style GG fill:#33b8ff,stroke:#ffffff,stroke-width:2px;\n  style HH fill:#66c1ff,stroke:#ffffff,stroke-width:2px;\n  style II fill:#99ccff,stroke:#ffffff,stroke-width:2px;\n\n  A[Checkout Repository] --&gt;|1. Checkout| B[Check if Run is Necessary]\n  B --&gt;|2. Determine Necessity| C[Set Up Git]\n  C --&gt;|3. Configure Git Settings| D[Set GIT Repo Environment Variables]\n  D --&gt;|4. Set Environment Variables| E[Display GIT Environment Variables]\n  E --&gt;|5. Display Variables| F[Print Latest Commit SHA]\n  F --&gt;|6. Print SHA and Path| G[Run Python Check]\n  G --&gt;|7. Execute Python Script| H[Write New CV]\n  H --&gt;|8. Write and Commit if Necessary| I[End]\n\n  style A fill:#4CAF50,stroke:#ffffff,stroke-width:2px;\n  style B fill:#4CAF50,stroke:#ffffff,stroke-width:2px;\n  style C fill:#4CAF50,stroke:#ffffff,stroke-width:2px;\n  style D fill:#4CAF50,stroke:#ffffff,stroke-width:2px;\n  style E fill:#4CAF50,stroke:#ffffff,stroke-width:2px;\n  style F fill:#4CAF50,stroke:#ffffff,stroke-width:2px;\n  style G fill:#4CAF50,stroke:#ffffff,stroke-width:2px;\n  style H fill:#4CAF50,stroke:#ffffff,stroke-width:2px;\n  style I fill:#4CAF50,stroke:#ffffff,stroke-width:2px;\n\n  A --&gt;|Begin Workflow| B\n  B --&gt;|Determine Necessity based on Git History| C\n  C --&gt;|Configure Git Settings| D\n  D --&gt;|Set Environment Variables| E\n  E --&gt;|Display Variables| F\n  F --&gt;|Print Commit SHA and Path| G\n  G --&gt;|Execute Python Script| H\n  H --&gt;|Write and Commit if Necessary| I\n\n  subgraph AA\n    A\n  end\n\n  subgraph BB\n    B\n  end\n\n  subgraph CC\n    C\n  end\n\n  subgraph DD\n    D\n  end\n\n  subgraph EE\n    E\n  end\n\n  subgraph FF\n    F\n  end\n\n  subgraph GG\n    G\n  end\n\n  subgraph HH\n    H\n  end\n\n  subgraph II\n    I\n  end</code></pre>"},{"location":"CMIP6Plus/Automations/generate_cv/","title":"[Py] Generate CV","text":"<p>The python script used to generate a cv. </p> <p>This is run by the action script [link here]. </p>"},{"location":"CMIP6Plus/Automations/generate_cv/#arguments","title":"Arguments","text":"<pre><code>Create CV \nusage: create_cv.py [-h] [-c COMMIT] [-d DATE] [-t TAG] [-b BRANCH] [-a API]\n\nGithub action script to create CVs\n\noptions:\n  -h, --help            show this help message and exit\n  -c COMMIT, --commit COMMIT\n                        Commit SHA\n  -d DATE, --date DATE  date_commit\n  -t TAG, --tag TAG     tag\n  -b BRANCH, --branch BRANCH\n                        branch\n  -a API, --api API     api_token\n</code></pre>"},{"location":"CMIP6Plus/Automations/generate_cv/#program-flow","title":"Program Flow","text":"<pre><code>\ngraph TB\n\nsubgraph \"Initialize Parameters\"\n    A[Set relative path]\n    B[Set CV prefix]\n    C[Define MIP tables prefix]\n    D[Define table prefix pattern]\nend\n\nsubgraph \"Argument Parsing\"\n    E[Parse commit, date, tag, branch, and API token]\nend\n\nsubgraph \"Define Functions\"\n    F[Read contents from GitHub]\n    G[Read JSON from GitHub]\n    H[Listify function]\n    I[Notnull function]\nend\n\nsubgraph \"Tunable Parameters\"\n    J[Define additional parameters]\nend\n\nsubgraph \"Other Parameters\"\n    K[Define additional parameters]\nend\n\nsubgraph \"Read from MIP Tables\"\n    L[Read source_type, frequency, realm, etc. from MIP tables]\nend\n\nsubgraph \"Main Section\"\n    M[Loop through structure elements]\n    N[Read table_id from GitHub]\n    O[Loop through experiments and update source_type]\n    P[Handle experiment_id entries]\n    Q[Handle activity_id entries]\n    R[Handle source_id entries]\nend\n\nsubgraph \"Metadata and Checksum\"\n    S[Get latest commit from MIP tables]\n    T[Update version metadata]\n    U[Calculate checksum]\nend\n\nsubgraph \"Checksum\"\n    V[Extract branch from branch argument]\n    W[Remove old branched CVs if branch is main]\n    X[Calculate checksum and compare with the old CV]\n    Y[Write updated CV to file]\nend\n\nA --&gt; E\nB --&gt; E\nC --&gt; E\nD --&gt; E\nE --&gt; J\nJ --&gt; L\nE --&gt; F\nE --&gt; G\nJ --&gt; F\nJ --&gt; G\nJ --&gt; H\nJ --&gt; I\nL --&gt; M\nN --&gt; M\nM --&gt; O\nO --&gt; P\nP --&gt; Q\nQ --&gt; R\nR --&gt; T\nT --&gt; U\nU --&gt; V\nV --&gt; W\nW --&gt; X\nX --&gt; Y\n</code></pre>"},{"location":"CMIP6Plus/Rules/activity_id/","title":"Activity ID","text":"Instructions <p>The rule guides describe what is required to submit a new item, and how to correctly fill out the forms and avoid submission errors. </p>"},{"location":"CMIP6Plus/Rules/activity_id/#name","title":"Name","text":"<p>This is where you specify the activity name. This must be unique and must not change. Often acronyms (e.g.<code>CMIP</code> and <code>LESFMIP</code>) are used to describe the activity. </p> <p>Rules :  Unicode, <code>[A-z]</code>, case-sensitive.  </p>"},{"location":"CMIP6Plus/Rules/activity_id/#activity-url","title":"Activity URL","text":"<p>To aid users to find out more about the activity, in CMIP6Plus we are requiring a URL describing it. This can be a fixed page on a website (ideal) or a link to the definition paper. </p> <p>Rules :  Existing URL string. Ideally this will work with both <code>http</code> and <code>https</code> </p>"},{"location":"CMIP6Plus/Rules/activity_id/#long-name","title":"Long Name","text":"<p>Finally we require a long (desciptive) name of the activity that may be used to better identify the activity. </p> <p>Rules :  Unicode, free-form, text. </p>"},{"location":"Data-Analysis-Tools/","title":"FEoCMIP-Data-Analysis-Tools","text":""},{"location":"Data-Analysis-Tools/#this-repository-contains-data-handling-tools-for-cmip-models-contributed-by-members-of-fresh-eyes-on-cmip","title":"This repository contains Data handling tools for CMIP models, contributed by members of Fresh Eyes on CMIP","text":""},{"location":"Data-Analysis-Tools/#this-repository-is-organized-into-the-following-categories","title":"This repository is organized into the following categories:","text":"<ul> <li>Preprocessing</li> <li>Analysis</li> <li>Visualization</li> <li>(ADD MORE HERE)</li> </ul>"},{"location":"Data-Analysis-Tools/#each-python-script-added-should-include-a-env-file-as-well","title":"Each python script added should include a .env file as well","text":""},{"location":"Data-Analysis-Tools/#the-general-layout-of-each-file-is-as-follows","title":"The general layout of each file is as follows:","text":"<ol> <li>Name and contact email of main contributor(s)</li> <li>Purpose of script/function</li> <li>Any other specific information users will need</li> <li>Executable code</li> </ol>"},{"location":"Data-Analysis-Tools/#contributor-information-and-affiliations","title":"Contributor Information and Affiliations","text":"<ul> <li>Keighan Gemmell, University of British Columbia, Canada \ud83c\udde8\ud83c\udde6</li> <li>J\u00falia Crespin Esteve, Universitat de Barcelona, Spain</li> <li>Anja Katzenberger, Potsdam Institute of Climate Impact Research, Germany </li> <li>ADD YOUR NAME AND AFFILIATION HERE </li> </ul>"},{"location":"Data-Analysis-Tools/Preprocessing/preprocess_parallel/","title":"preprocess parallel","text":"<p>This file contains a wrapped preprocessing function that detrends, removes seasonal cycle, and executes a rolling average</p>"},{"location":"Data-Analysis-Tools/Preprocessing/preprocess_parallel/#note-on-running","title":"Note on running:","text":"<ul> <li>There is also a normalization function </li> <li>To run this script you will need ensure xarray is installed</li> <li></li> </ul> <p>Note</p> <p>Remember to change file paths to where your data is stored </p> <pre><code>    #Created by Keighan Gemmell (keighan@chem.ubc.ca)\n    #This file contains a wrapped preprocessing function that detrends, removes seasonal cycle, and executes a rolling average\n    #There is also a normalization function \n    #To run this script you will need ensure xarray is installed\n    #Change file paths to where your data is stored \n\n    import xarray as xr\n    import numpy as np\n    from multiprocessing import Pool\n    import s3fs\n    import geocat.comp\n    import time\n    import pandas as pd\n    import json\n    import os\n    import sys\n    import pyximport\n    pyximport.install(setup_args={\"include_dirs\":np.get_include()},\n                    reload_support=True)\n    sys.path.insert(0,'') #fill in path here\n\n    ### Set of functions for executing preprocessing of CMIP6 data\n    ### This code used an old AWS S3 storage system to access CMIP6 data, you will need to add the lines to pull data from wherever you store it\n\n    df = pd.read_csv(\"\") #name of file here\n\n    proc = 40\n\n    def getData(query:dict):\n        '''\n        Load CMIP6 data into xarray dataframe\n        query (dict or str) - dict or str with data information\n                            - if dict format as {'param':'value','param2':['val1','val2']}\n        '''\n        # Create query string for pandas.DataFrame.query\n        if type(query) is dict:\n            inputStr = \" &amp; \".join([\"{0}=='{1}'\".format(param, query[param]) for param in query])\n        elif type(query) is str: # if its already a string, pass through\n            inputStr=query\n\n        # Searches cmip6 data csv for datasets that match given parameters\n        df_subset = df.query(inputStr)\n        if df_subset.empty:\n            print('data not available for '+inputStr)\n        else:\n            # load data\n            for v in df_subset.zstore.values:\n                zstore = v\n                mapper = fs.get_mapper(zstore)\n                ### !!!! Note decode times is false so we can use integer time values !!!!\n                ### open_zarr, so datasets are not loaded yet\n                return_ds = xr.open_zarr(mapper, consolidated=True,decode_times=False)\n        return(return_ds)\n\n    def removeSC(x:np.ndarray):\n        '''\n        Removes seasonal cycle from monthly data\n        x (np.ndarray) - 3D (time,lat,lon) numpy array\n        '''\n        nt,nx,ny = x.shape # get array dimensions\n        nyears = nt//12\n        # get month means\n        monmean = np.mean(x.reshape(nyears,12,nx,ny),axis=0)\n        for m in range(12): #for each month\n            x[m::12] = x[m::12] - monmean[m]\n        return x\n\n    def detrend(x:np.ndarray,time:np.ndarray):\n        '''\n        remove degree three polynomial fit\n        x (np.ndarray) : 3D (time, lat, lon) numpy array\n        time (np.ndarray) : 1D (time) array \n        '''\n        nt,nx,ny = x.shape\n        xtemp = x.reshape(nt,nx*ny)\n        p = np.polyfit(time, xtemp, deg=3)\n        print(p.shape)\n        fit = p[0]*(time[:,np.newaxis] **3)+ p[1]*(time[:,np.newaxis]**2) + p[2]*(time[:,np.newaxis]) + p[3]\n        return x - fit.reshape(nt,nx,ny)\n\n    def preprocess(data:np.ndarray, tdata:np.ndarray, window:int = 31,proc:int = 40):\n        '''\n        Executes the three steps of the preprocessing (deseasonalize, detrend, normalize)\n        data (np.ndarray) : data to process\n        t (np.ndarray) : time values\n        window (integer) : years for the rolling average\n        proc (int) : number of processes for multiprocessing\n        '''\n\n        ### remove seasonal cycle\n        t1 = time.time()\n        print('Deseasonalize')\n        deseas = removeSC(data)\n        t2 = time.time()\n        print('Time : ', t2-t1)\n\n        ### remove cubic fit\n        print('Detrend')\n        print(tdata.shape)\n        detre = detrend(deseas,tdata)\n        t3 = time.time()\n        print('Time : ',t3-t2)\n\n        x = detre\n\n        ## function for normalizing - written for passing to multiprocessing\n        global normalize\n        def normalize(t):\n            '''\n            Calculate anomaly and normalize (repeat boundary values) for monthly data\n            averages across years (12 time step skips)\n            x (np.ndarray) - integer values\n            t (integer) - time\n            window (integer) - years in the averaging window must be odd for now\n            '''\n            assert window%2 == 1\n            tmax = x.shape[0]\n            halfwindow = window//2\n            yr = t//12\n            mon = t%12\n            selx = np.zeros_like(x[:window])\n            # get rolling window (backfills/forward fills with first/last value)\n            if t-halfwindow*12 &lt; 0:\n                selx[:halfwindow - yr] = x[mon]\n                selx[halfwindow-yr:] = x[mon:t+halfwindow*12+1:12]\n            elif t+halfwindow*12+1 &gt; tmax:\n                selx[halfwindow + (tmax//12 - yr):] = x[tmax- 12 + mon]\n                selx[:halfwindow + (tmax//12 - yr)] = x[t - halfwindow*12::12]\n            else:\n                selx = x[t-halfwindow*12:t+halfwindow*12+1:12]\n            # calculate normalized\n            normed = (x[t] - np.mean(selx,axis=0))/np.std(selx,axis=0)\n            return normed\n        ### run normalization\n        print('Normalize')\n        ntime = x.shape[0]\n\n        # parallelize normalizing across time (trivially parallel)\n        with Pool(processes=proc) as pool: \n            outdata = pool.map(normalize, range(ntime))\n        t4 = time.time()\n        print('Time : ',t4-t3)\n        return np.array(outdata,dtype=np.float32)\n\n    def run_preprocess(experiment:str, modelName:str, member:str, variables_in:list,\n                variables_out:list, attribute_path:str = 'variable_defs.json',\n                out_path:str = None,lf_query:str = None,\n                append:bool=False,frequency:str='Amon'):\n        '''\n        Wrapper function that executes the preprocessing pipeline\n        experiment (str) : experiment name (experiment_id)\n        modelName (str) : model name (source_id)\n        member (str) : ensemble member code (member_id) r*i*p*f*\n        variables_in (list) : list of variables to grab from CMIP6 archive\n        variables_out (list) : list of variables to calculate and output\n        attribute_path (str) : path to a json file with variable descriptions.\n            Note if you request a variable in variables_out that is not a CMOR variable, it must\n            be defined in the attribute .json\n        out_path (str) : file name for output\n        lf_query (str) : query string to pass to pandas.DataFram.query  recommended to pass this,\n            otherwise the script is likely to fail due to not finding sftlf variable\n            set to False to skip adding the landfraction, set to None to attempt to find land fraction\n            for the selected experiment and ensemble member\n        append (str) : append variables_out to an existing netcdf file\n        frequency (str) : CMIP table to get data from (e.g. Amon, Omon, Aday - table_id). \n        '''\n        # Default out_path\n        if out_path is None: \n            out_path = ''.format(modelName, member, experiment)\n\n        print('Preprocessing for {0} {1} {2}'.format(modelName,experiment,member))\n\n        # if we are appending to an existing netcdf\n        # load the dataset and determine the existing variables\n        if append:\n            if os.path.isfile(out_path):\n                existing = xr.open_dataset(out_path)\n                existing_variables = list(existing.variables)\n                del existing\n            else:\n                print('append = True, but no existing file. Setting to append = False')\n                append = False\n\n        ## Load in data (could make faster with open_mfdataset?)\n        dict_query = {'source_id':modelName, 'table_id':frequency, 'experiment_id':experiment, 'member_id':member}\n        data = {}\n        for var in variables_in:\n            dict_query['variable_id'] = var\n            data[var] = getData(dict_query)\n\n        # Load land fraction data\n        if lf_query is None:\n            # if query isn't provided, attempt to load from current experiment\n            lf_query  = \"source_id=='{0}' &amp; table_id=='fx' &amp; experiment_id=='{1}' &amp;  member_id=='{2}' &amp; variable_id=='sftlf'\".format(modelName,experiment,member)\n        elif lf_query: # set lf_query=False to skip\n            data['sftlf'] = getData(lf_query) ## land area fraction as %\n\n        # Attributes for derived variables\n        d_attr = json.load(open(attribute_path))\n\n        processed = {} # preprocessed data\n        orig = {} # raw data\n        for var in variables_out:\n            if append and var in existing_variables:\n                # skip existing variables if in append mode\n                print('{0} already exists, skipping'.format(var))\n                variables_out.remove(var)\n                continue\n            print('-----------------')\n            print(var)\n            print('-----------------')\n            if var in variables_in: \n                # If taking variable directly from CMIP\n                signs = [1]\n                variables = [var]\n                attributes = {'long_name': data[var][var].long_name, 'units':data[var][var].units}\n            elif var in d_attr: \n                # If calculating a variable from CMIP variables\n                signs = d_attr[var]['signs']\n                attributes = d_attr[var]\n                variables = d_attr[var]['variables']\n            else: # Something's wrong (missing variable or definition)\n                print('missing variable definition in {0}'.format(attribute_path))\n                continue\n            if 'integral' in attributes:\n                # if we are integrating a 3D variable\n                processed[var], orig[var] = calc_var_integral(data,variables[0],var,attributes = attributes)\n            else:\n                processed[var], orig[var] = calc_var(data, variables, signs, var,attributes = attributes)\n\n        # Cast the fixed land fraction data into a time series\n        if lf_query: # set lf_query=False to skip\n            # tile in time\n            sftlfOut, b2 = xr.broadcast(data['sftlf'].sftlf, data[variables_in[0]][variables_in[0]], exclude=('lat','lon'))\n            sftlfOut=sftlfOut.where(sftlfOut==0,1) ### data has values as 0 for ocean or 100 for land sa making 100 as 1\n            lsMask = xr.DataArray(name='lsMask', data=sftlfOut.load(), attrs={'long_name':'land_sea_mask', 'Description':'land fraction of each grid cell 0 for ocean and 1 for land'}, \n                                coords={'time': data[variables_in[0]].time,'lat': data['sftlf'].lat,'lon': data['sftlf'].lon})\n\n        # change time to original values (time values get altered in calc_var)\n        for var in variables_out:\n            processed[var]['time'] = data[variables_in[0]].time\n            orig[var]['time'] = data[variables_in[0]].time\n\n        # Save one DataArray as dataset\n        var = variables_out[0]\n        output_ds = processed[var].to_dataset(name = var+'_pre')\n        output_ds[var] = orig[var]\n        for var in variables_out[1:]:\n            # Add next DataArray to existing dataset (ds)\n            output_ds[var+'_pre'] = processed[var]\n            output_ds[var] = orig[var]\n        # add the landfraction query\n        if lf_query:\n            output_ds['lsMask'] = lsMask\n        print('Write to file')\n        if append:\n            output_ds.to_netcdf(path=out_path,mode='a',format='NETCDF4')\n        else:\n            output_ds.to_netcdf(path=out_path,mode='w',format='NETCDF4')\n</code></pre>"},{"location":"Data-Analysis-Tools/Visualisation/change_in_windvector/","title":"Change in Wind speed and Direction","text":"<p>Created by anjakatzenberger</p> <p>This code provides changes in wind speed and wind direction for a subset of CMIP6 models</p> <ol> <li>The first figure (a panel of 2x3 wind fields) is written for 6 CMIP6 models</li> <li>The second figure gives a multi model mean of the models given</li> <li>The input data is preprocessed using CDOs (selected time period, selected altitude of winds, as well as mean over time for specific months)</li> </ol>"},{"location":"Data-Analysis-Tools/Visualisation/change_in_windvector/#adapt-the-preprocessing-as-adequate-for-your-research-question","title":"Adapt the preprocessing as adequate for your research question","text":""},{"location":"Data-Analysis-Tools/Visualisation/change_in_windvector/#example-template-of-the-program-structure","title":"Example template of the program structure.","text":"<pre><code>graph TD\n  subgraph \"Initialize Directories\"\n    A[udir_future]\n    B[vdir_future]\n    C[udir]\n    D[vdir]\n    E[dir_save]\n  end\n\n  subgraph \"List Files\"\n    F[List files in udir_future]\n    G[List files in vdir_future]\n    H[List files in udir]\n    I[List files in vdir]\n  end\n\n  subgraph \"Create Wind Fields\"\n    J[Loop through models]\n    K[Load u and v data]\n    L[Calculate wind speed]\n    M[Plot wind fields]\n    N[Save figure]\n  end\n\n  subgraph \"Multi-Model Mean\"\n    O[Create arrays for wind speed, ua_diff, va_diff]\n    P[Loop through models]\n    Q[Load u and v data]\n    R[Calculate ua_diff and va_diff]\n    S[Calculate mean wind speed]\n    T[Plot mean wind speed]\n    U[Save figure]\n  end\n\n  A --&gt; J\n  B --&gt; J\n  C --&gt; J\n  D --&gt; J\n  E --&gt; M\n  F --&gt; J\n  G --&gt; J\n  H --&gt; J\n  I --&gt; J\n  J --&gt; K\n  K --&gt; L\n  L --&gt; M\n  M --&gt; N\n  N --&gt; |Repeat for each model| J\n  O --&gt; P\n  P --&gt; Q\n  Q --&gt; R\n  R --&gt; O\n  R --&gt; S\n  S --&gt; T\n  T --&gt; U\n</code></pre>"},{"location":"MIP_Tables/","title":"mip-cmor-tables","text":"<p>JSON tables to create Model Intercomparison Project (MIP) datasets</p> <p>A quick intro on how to make use of these tables is available on the Wiki.</p>"},{"location":"MIP_Tables/#contributors","title":"Contributors","text":"<p>Thanks to our contributors!</p>"},{"location":"mailing_lists/whitelisting/","title":"Whitelisting the CMIP server","text":"<p>As our mail server is relatively new, although all the required message headers and metadata have been set, emails may occasionally end up in the spam/quarantine folder. </p> <p>If you are having trouble recieving emails, or these are being flagged, you may have to add the WCRP-cmip domain to your whitelist. The most common solutions are provided below, although should you have any others, feel free to contact us, and we will add them to the list. </p>"},{"location":"mailing_lists/whitelisting/#microsoft","title":"Microsoft","text":""},{"location":"mailing_lists/whitelisting/#1-open-the-safe-senders-list","title":"1. Open the safe-senders list","text":"<p>https://outlook.office365.com/mail/options/mail/junkEmail/safeSendersDomainsV2</p>"},{"location":"mailing_lists/whitelisting/#2-add-the-wcrp-cmip-domain","title":"2. Add the WCRP-CMIP domain","text":"<p>We now need to add our domain to be whitelisted. The domains are: <pre><code>wcrp-cmip.org\nmail.wcrp-cmip.org\n</code></pre></p> <p></p>"}]}